{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from preprocessing import getFilename,getData\n",
    "\n",
    "#Config = tf.ConfigProto(device_count = {'GPU' : 0})\n",
    "\n",
    "source_route = '/home/kexin/Documents/project/CASP_SCWRL'\n",
    "tensorboard_route = '/home/kexin/Documents/project/model/train'\n",
    "model_route = \"/home/kexin/Documents/project/model/\"\n",
    "\n",
    "batch_size = 20\n",
    "epoch = 15\n",
    "\n",
    "x = tf.placeholder('float')\n",
    "y = tf.placeholder('float')\n",
    "test_pred = tf.placeholder('float')\n",
    "\n",
    "train_filenames, train_binsizes = getFilename(source_route,400)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_filenames)\n",
    "train_dataset = train_dataset.map( lambda text : tf.py_func(getData,[text], [tf.float64, tf.int32]))\n",
    "train_dataset = train_dataset.repeat(epoch)\n",
    "#train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "train_iterator = train_dataset.make_one_shot_iterator()\n",
    "next_train_element = train_iterator.get_next()\n",
    "\n",
    "\n",
    "test_filenames, test_binsizes = getFilename(source_route, 50)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_filenames)\n",
    "test_dataset = test_dataset.map( lambda text : tf.py_func(getData,[text], [tf.float64, tf.int32]))\n",
    "#test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "test_iterator = test_dataset.make_one_shot_iterator()\n",
    "next_test_element = test_iterator.get_next()\n",
    "\n",
    "keep_rate = 0.8\n",
    "keep_prob = tf.placeholder(tf.float64)\n",
    "\n",
    "def conv3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='VALID')\n",
    "\n",
    "def maxpool3d(x):\n",
    "    #                        size of window         movement of window\n",
    "    return tf.nn.max_pool3d(x, ksize=[1,3,3,3,1], strides=[1,2,2,2,1], padding='VALID')\n",
    "    #Our output tensor produced by max_pooling2d() the 2x2 filter reduces height and width by 50% each.\n",
    "\n",
    "def convolutional_neural_network(x):\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([3,3,3,11,16])),\n",
    "               'W_conv2':tf.Variable(tf.random_normal([3,3,3,16,32])),\n",
    "               'W_conv3':tf.Variable(tf.random_normal([3,3,3,32,32])),\n",
    "               'W_conv4':tf.Variable(tf.random_normal([3,3,3,32,64])),\n",
    "               'W_conv5':tf.Variable(tf.random_normal([3,3,3,64,128])),\n",
    "               'W_conv6':tf.Variable(tf.random_normal([3,3,3,128,128])),\n",
    "               'W_conv7':tf.Variable(tf.random_normal([3,3,3,128,256])),\n",
    "               'W_conv8':tf.Variable(tf.random_normal([3,3,3,256,512])),\n",
    "               #fc: first element is determined by result of layers below.\n",
    "               'W_fc1':tf.Variable(tf.random_normal([512,256])),\n",
    "               'W_fc2':tf.Variable(tf.random_normal([256,128])),\n",
    "               'out':tf.Variable(tf.random_normal([128, 10]))}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([16])),\n",
    "              'b_conv2':tf.Variable(tf.random_normal([32])),\n",
    "              'b_conv3':tf.Variable(tf.random_normal([32])),\n",
    "              'b_conv4':tf.Variable(tf.random_normal([64])),\n",
    "              'b_conv5':tf.Variable(tf.random_normal([128])),\n",
    "              'b_conv6':tf.Variable(tf.random_normal([128])),\n",
    "              'b_conv7':tf.Variable(tf.random_normal([256])),\n",
    "              'b_conv8':tf.Variable(tf.random_normal([512])),\n",
    "              'b_fc1':tf.Variable(tf.random_normal([256])),\n",
    "              'b_fc2':tf.Variable(tf.random_normal([128])),\n",
    "              'out':tf.Variable(tf.random_normal([10]))}\n",
    "\n",
    "    #The methods in the layers module for creating convolutional and pooling layers for two-dimensional \n",
    "    #image data expect input tensors to have a shape of [batch_size, image_height, image_width, channels] by default. \n",
    "    x = tf.reshape(x, shape=[-1, 120, 120, 120, 11])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool3d(conv1)\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = tf.layers.batch_normalization(conv2)\n",
    "    conv2 = maxpool3d(conv2)\n",
    "    \n",
    "    conv3 = tf.nn.relu(conv3d(conv2, weights['W_conv3']) + biases['b_conv3'])\n",
    "    conv3 = tf.layers.batch_normalization(conv3)\n",
    "\n",
    "    conv4 = tf.nn.relu(conv3d(conv3, weights['W_conv4']) + biases['b_conv4'])\n",
    "    conv4 = tf.layers.batch_normalization(conv4)\n",
    "    conv4 = maxpool3d(conv4)\n",
    "    \n",
    "    conv5 = tf.nn.relu(conv3d(conv4, weights['W_conv5']) + biases['b_conv5'])\n",
    "    conv5 = tf.layers.batch_normalization(conv5)\n",
    "    \n",
    "    conv6 = tf.nn.relu(conv3d(conv5, weights['W_conv6']) + biases['b_conv6'])\n",
    "    conv6 = tf.layers.batch_normalization(conv6)\n",
    "\n",
    "    conv7 = tf.nn.relu(conv3d(conv6, weights['W_conv7']) + biases['b_conv7'])\n",
    "    conv7 = tf.layers.batch_normalization(conv7)\n",
    "    \n",
    "    conv8 = tf.nn.relu(conv3d(conv7, weights['W_conv8']) + biases['b_conv8'])\n",
    "    conv8 = tf.layers.batch_normalization(conv8)\n",
    "    conv8 = maxpool3d(conv8)\n",
    "\n",
    "    fc = tf.reshape(conv8,[-1, 1*1*1*512])\n",
    "    \n",
    "    fc1 = tf.nn.relu(tf.matmul(fc, weights['W_fc1'])+biases['b_fc1'])\n",
    "    \n",
    "    fc2 = tf.nn.relu(tf.matmul(fc1, weights['W_fc2'])+biases['b_fc2'])\n",
    "    \n",
    "    fc2 = tf.nn.dropout(fc2, keep_rate)\n",
    "\n",
    "    output = tf.matmul(fc2, weights['out'])+biases['out']\n",
    "\n",
    "    return output\n",
    "\n",
    "def loss_function(prediction, y):\n",
    "    \n",
    "    hinge_loss = tf.reduce_mean(tf.losses.hinge_loss(labels=y, logits=prediction))\n",
    "    \n",
    "    tf.summary.scalar(\"hinge_loss\", hinge_loss)\n",
    "    \n",
    "    return hinge_loss\n",
    "\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = convolutional_neural_network(x)\n",
    "    class_prediction = tf.nn.softmax(prediction)\n",
    "    \n",
    "    cost = loss_function(prediction, y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate= 0.0001).minimize(cost)\n",
    "    \n",
    "    correct_pred = tf.equal(tf.argmax(test_pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "\n",
    "    with tf.Session(config = Config) as sess:\n",
    "        \n",
    "        merged = tf.summary.merge_all()\n",
    "        writer = tf.summary.FileWriter(tensorboard_route, sess.graph)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for ep in range(epoch):\n",
    "            \n",
    "            if epoch!=0 and epoch%2 == 0:\n",
    "                \n",
    "                saver = tf.train.Saver()\n",
    "                save_route = model_route + str(ep) + \".ckpt\" \n",
    "                saver.save(sess,save_route)\n",
    "        \n",
    "\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            for binsize in train_binsizes:\n",
    "                feature_array = []\n",
    "                label_array = []\n",
    "                \n",
    "                pred_array = []\n",
    "                try:\n",
    "                    \n",
    "                    bin_loss = 0\n",
    "                    for bs in range(binsize):\n",
    "\n",
    "                        feature, label = sess.run(next_train_element)\n",
    "                        feature_array.append(feature)\n",
    "                        label_array.append(label)\n",
    "                    \n",
    "                    #p = sess.run([prediction], feed_dict={x:feature_array})\n",
    "                    #print (\"predictions:\", p)\n",
    "                        #pred_array.append(sess.run(prediction, feed_dict={x: feature}))\n",
    "                    \n",
    "                    _, c = sess.run([optimizer, cost], feed_dict={x: feature_array, y: label_array})\n",
    "                    \n",
    "                    print(\"loss: \", c)\n",
    "                    \n",
    "                    epoch_loss += c\n",
    "\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "\n",
    "            print('Epoch', ep, 'completed out of',epoch,'loss:',epoch_loss)\n",
    "            \n",
    "            \n",
    "            \n",
    "            total_accuracy = 0\n",
    "            \n",
    "            for binsize in test_binsizes:\n",
    "                \n",
    "                test_x_array = []\n",
    "                test_y_array = []\n",
    "                \n",
    "                test_pred_array = []\n",
    "                \n",
    "                try:\n",
    "                    for bs in range(binsize):\n",
    "                        test_x, test_y = sess.run(next_test_element)\n",
    "                        test_x_array.append(test_x)\n",
    "                        test_y_array.append(test_y)\n",
    "                        \n",
    "                        test_pred_array.append(sess.run(class_prediction, feed_dict={x: test_x}))\n",
    "                        \n",
    "                        a =  sess.run(accuracy, feed_dict={test_pred: test_pred_array, y:test_y_array})\n",
    "                        total_accuracy += a\n",
    "                        \n",
    "                        print(\"batch Accuracy: \", a)\n",
    "                    \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                        break\n",
    "                        \n",
    "            print('Accuracy:', total_accuracy / len(test_binsizes))\n",
    "\n",
    "train_neural_network(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
